{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input image: (1653, 2336)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################### DATA INPUT BLOCK ########################################3\n",
    "\n",
    "#read your file\n",
    "file=r'Dict_9.tiff'\n",
    "img_all = cv2.imread(file,0)\n",
    "print 'Shape of the input image:',img_all.shape\n",
    "\n",
    "#read templates for all of the numbers and minus sign\n",
    "templates = []\n",
    "number_names=['0','1','2','3','4','5','6','7','8','9','-']\n",
    "for number in number_names:\n",
    "    name = number + '.png'\n",
    "    templates.append(cv2.imread(name,0))\n",
    "\n",
    "# Cut only the right part of the page\n",
    "img = img_all[:,1200:]\n",
    "\n",
    "# Save it\n",
    "cv2.imwrite('Dict_9_half.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ HELPER FUNCTIONS BLOCK #############################\n",
    "\n",
    "# Distance calculation \n",
    "def dist(a,b,c,d):\n",
    "    return abs(a-c) + abs(b-d)\n",
    "\n",
    "\n",
    "# Combination of the line segments into the full width lines\n",
    "def combineHLines(lines, threshold):\n",
    "    newLines = []\n",
    "    sortLines = []\n",
    "    #Sort the lines\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            # sort all lines from left to right\n",
    "            if x1>x2:\n",
    "                x_mem =  x1\n",
    "                y_mem = y1\n",
    "                x1 = x2\n",
    "                y1 = y2\n",
    "                x2 = x_mem\n",
    "                y2 = y_mem\n",
    "            sortLines.append([x1,y1,x2,y2])\n",
    "            # if the line starts from the begining of the line\n",
    "            if (x1>150) and (x1<170):\n",
    "                newLines.append([x1,y1,x2,y2])\n",
    "    # extendlines\n",
    "    for i in range(len(newLines)):\n",
    "        line = newLines[i]\n",
    "        x1 = line[0]\n",
    "        y1 = line[1]\n",
    "        x2 = line[2]\n",
    "        y2 = line[3]\n",
    "        Expandable = True\n",
    "        while Expandable and x2<940:\n",
    "            Expandable = False\n",
    "            minDist = 1000\n",
    "            for lineS in sortLines:\n",
    "                xi1 = lineS[0]\n",
    "                yi1 = lineS[1]\n",
    "                xi2 = lineS[2]\n",
    "                yi2 = lineS[3]\n",
    "                if dist(xi1,yi1,x2,y2)<minDist:\n",
    "                    minDist = dist(xi1,yi1,x2,y2)\n",
    "                    line_mem = lineS\n",
    "            if minDist < threshold:\n",
    "                x2 = line_mem[2]\n",
    "                y2 = line_mem[3]\n",
    "                Expandable = True\n",
    "                newLines[i][2] = x2\n",
    "                newLines[i][3] = y2\n",
    "                \n",
    "    #delete unfinished lines\n",
    "    finalLines = []\n",
    "    for line in newLines:\n",
    "        if line[2] > 940:\n",
    "            finalLines.append(line)\n",
    "    return finalLines\n",
    "\n",
    "# Sorting of countours and generation of bounding boxes\n",
    "def sort_contours(cnts, method=\"left-to-right\"):\n",
    "    # initialize the reverse flag and sort index\n",
    "    reverse = False\n",
    "    i = 0\n",
    "    # handle if we need to sort in reverse\n",
    "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "        reverse = True\n",
    "    # handle if we are sorting against the y-coordinate rather than\n",
    "    # the x-coordinate of the bounding box\n",
    "    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "        i = 1\n",
    "    # construct the list of bounding boxes and sort them from top to\n",
    "    # bottom\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "    key=lambda b:b[1][i], reverse=reverse))\n",
    "    # return the list of sorted contours and bounding boxes\n",
    "    return (cnts, boundingBoxes)\n",
    "\n",
    "\n",
    "# Get the sub cell coordinates for the number\n",
    "def getNumberFrame(yo,y1,x0,x1):\n",
    "    frame = img[y0:y1,x0:x1]\n",
    "    thresh, frame_T = cv2.threshold(frame,128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    return frame_T, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected skew to be -0.35311556856242077 degrees\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################### DESKEW BLOCK ##############################################\n",
    "\n",
    "#thresholding the image to a binary image\n",
    "thresh,img_bin = cv2.threshold(img,128,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "#inverting the image\n",
    "img_bin = 255-img_bin\n",
    "\n",
    "# countcol(width) of kernel as 100th of total width\n",
    "kernel_len = np.array(img).shape[1]//100\n",
    "\n",
    "# Defining a horizontal kernel to detect all horizontal lines of image\n",
    "hor_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_len, 1))\n",
    "\n",
    "#Use horizontal kernel to detect and save the horizontal lines in a jpg\n",
    "image_2 = cv2.erode(img_bin, hor_kernel, iterations=3)\n",
    "horizontal_lines = cv2.dilate(image_2, hor_kernel, iterations=3)\n",
    "\n",
    "# Apply edge detection method on the image \n",
    "edges = cv2.Canny(horizontal_lines,50,150,apertureSize = 3)\n",
    "  \n",
    "rho = 1  # distance resolution in pixels of the Hough grid\n",
    "theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "threshold = 15  # minimum number of votes (intersections in Hough grid cell)\n",
    "min_line_length = 50  # minimum number of pixels making up a line\n",
    "max_line_gap = 20  # maximum gap in pixels between connectable line segments\n",
    "line_image = np.copy(img) * 0  # creating a blank to draw lines on\n",
    "\n",
    "# Run Hough on edge detected image\n",
    "# Output \"lines\" is an array containing endpoints of detected line segments\n",
    "lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),\n",
    "                    min_line_length, max_line_gap)\n",
    "\n",
    "# Filter the lines to get full width lines\n",
    "newLines = combineHLines(lines,60)\n",
    "\n",
    "# collect angles\n",
    "angles = []\n",
    "for line in newLines:\n",
    "    x1 = line[0]\n",
    "    y1 = line[1]\n",
    "    x2 = line[2]\n",
    "    y2 = line[3]\n",
    "    angle = float((y2-y1)/(x2-x1))\n",
    "    angles.append(angle)\n",
    "    cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),5)\n",
    "             \n",
    "# Save line detection output\n",
    "cv2.imwrite('Dict_9_line_detection.jpg',line_image) \n",
    "         \n",
    "angle = np.mean(angles)*180/np.pi\n",
    "print 'Detected skew to be', angle, 'degrees'\n",
    "\n",
    "# rotate the image to deskew it\n",
    "(h, w) = img.shape[:2]\n",
    "center = (w // 2, h // 2)\n",
    "M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "img_deskew = cv2.warpAffine(img, M, (w, h),\n",
    "                         flags=cv2.INTER_CUBIC, \n",
    "                         borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "# Save it\n",
    "cv2.imwrite('Dict_9_half_rotated.jpg',img_deskew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cell height: 82.1\n",
      "Average cell width: 75.7875\n"
     ]
    }
   ],
   "source": [
    "########################## CELL DETECTION BLOCK #########################################################\n",
    "\n",
    "# thresholding the image to a binary image\n",
    "thresh,img_bin = cv2.threshold(img_deskew,128,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "# inverting the image\n",
    "img_bin = 255-img_bin\n",
    "\n",
    "# countcol(width) of kernel as 100th of total width\n",
    "kernel_len = np.array(img).shape[1]//100\n",
    "\n",
    "# Defining a vertical kernel to detect all vertical lines of image\n",
    "ver_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_len))\n",
    "\n",
    "# Defining a horizontal kernel to detect all horizontal lines of image\n",
    "hor_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_len, 1))\n",
    "\n",
    "# A kernel of 2x2\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "\n",
    "# Use vertical kernel to detect and save the vertical lines in a jpg\n",
    "image_1 = cv2.erode(img_bin, ver_kernel, iterations=3)\n",
    "vertical_lines = cv2.dilate(image_1, ver_kernel, iterations=3)\n",
    "\n",
    "# Use horizontal kernel to detect and save the horizontal lines in a jpg\n",
    "image_2 = cv2.erode(img_bin, hor_kernel, iterations=3)\n",
    "horizontal_lines = cv2.dilate(image_2, hor_kernel, iterations=3)\n",
    "\n",
    "# Combine horizontal and vertical lines in a new third image, with both having same weight.\n",
    "img_vh = cv2.addWeighted(vertical_lines, 0.5, horizontal_lines, 0.5, 0.0)\n",
    "\n",
    "# Eroding and thesholding the image\n",
    "img_vh = cv2.erode(~img_vh, kernel, iterations=2)\n",
    "thresh, img_vh = cv2.threshold(img_vh,128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "#cv2.imwrite(\"Dict_9_cell_detection.jpg\", img_vh)\n",
    "bitxor = cv2.bitwise_xor(img,img_vh)\n",
    "bitnot = cv2.bitwise_not(bitxor)\n",
    "\n",
    "#Plotting the generated image\n",
    "cv2.imwrite(\"Dict_9_cell_detection.jpg\", img_vh)\n",
    "\n",
    "# Detect contours for following box detection\n",
    "contours, hierarchy = cv2.findContours(img_vh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Sort all the contours by top to bottom.\n",
    "contours, boundingBoxes = sort_contours(contours, method=\"top-to-bottom\")\n",
    "\n",
    "# Filter contours\n",
    "c_filtered = []\n",
    "width = []\n",
    "height = []\n",
    "for c in contours:\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    if (w>70 and w<80 and h>60):\n",
    "        c_filtered.append([x,y,w,h])\n",
    "        width.append(w)\n",
    "        height.append(h)\n",
    "        \n",
    "print 'Average cell height:',np.mean(height)\n",
    "print 'Average cell width:',np.mean(width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 1\n",
      "Iteration 1 2\n",
      "54 45 -38\n",
      "Iteration 2 1\n",
      "Iteration 2 2\n",
      "59 40\n",
      "\n",
      "-67\n",
      "Iteration 3 1\n",
      "Iteration 3 2\n",
      "69 -56 31\n",
      "Iteration 4 1\n",
      "Iteration 4 2\n",
      "42 56\n",
      "\n",
      "-35\n",
      "Iteration 5 1\n",
      "Iteration 5 2\n",
      "18 51 -11\n",
      "Iteration 6 1\n",
      "Iteration 6 2\n",
      "34 55\n",
      "\n",
      "-68\n",
      "Iteration 7 1\n",
      "Iteration 7 2\n",
      "13 56 -19\n",
      "Iteration 8 1\n",
      "Iteration 8 2\n",
      "49 50 -64\n",
      "Iteration 9 1\n",
      "Iteration 9 2\n",
      "\n",
      "Iteration 10 1\n",
      "Iteration 10 2\n",
      "16 52\n"
     ]
    }
   ],
   "source": [
    "#########################################   OCR BLOCK   #########################################\n",
    "\n",
    "# iterate through all detected cells\n",
    "iterator = 0\n",
    "container = []\n",
    "for x,y,w,h in c_filtered:\n",
    "    if iterator < 10:\n",
    "        iterator += 1\n",
    "        for i in range(3):\n",
    "            nw = int(w / 3 + 4)\n",
    "            y1 = y + nw * i\n",
    "            y2 = y + nw * (i+1)-5\n",
    "            x1 = x + 10\n",
    "            x2 = x + w - 20\n",
    "            frame = img_deskew[y1:y2,x+10:x+w-20]\n",
    "            if i == 0:\n",
    "                pFrame = frame\n",
    "            else:\n",
    "                print 'Iteration',iterator, i\n",
    "                pFrame = np.hstack((pFrame,frame))\n",
    "            cv2.imwrite(name, frame)\n",
    "        name = 'Comb' + str(iterator) + '.jpg'\n",
    "        cv2.imwrite(name, pFrame)\n",
    "        primer = pytesseract.image_to_string(pFrame)\n",
    "        container.append(primer)\n",
    "        print primer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
